# ğŸ“š Guide d'utilisation - AnimeSamaScraper (Linux)

## ğŸ¯ RÃ©sumÃ© des amÃ©liorations

Les scripts ont Ã©tÃ© optimisÃ©s pour un dÃ©ploiement et une maintenance 100% Linux avec :
- ğŸ“– Comptage prÃ©cis des pages pour chaque chapitre
- ğŸ“Š Statistiques complÃ¨tes (mangas, chapitres, pages)
- ğŸ”„ Automatisation complÃ¨te du processus avec systemd
- ğŸ’¾ Stockage structurÃ© en base de donnÃ©es MongoDB
- ğŸ“ˆ Suivi des mÃ©triques de contenu
- ğŸ› ï¸ **Scripts de maintenance Linux automatisÃ©s**
- ğŸ” **Surveillance continue du service**
- ğŸ“§ **Alertes et notifications (extensible)**

### ğŸš€ Workflow complet de mise Ã  jour (Linux)
1. **DÃ©veloppement local** â†’ Test avec `python test_updated_scripts.py`
2. **Commit et push** â†’ `git add . && git commit -m "..." && git push`
3. **Mise Ã  jour production** â†’ `./update_service.sh`
4. **Surveillance** â†’ `./monitor_service.sh --detailed`

## ğŸ“ Scripts disponibles

### 1. `main.py` (Script principal)
- âœ… **FonctionnalitÃ© principale** : Scraping complet des mangas avec comptage des pages
- âœ… **Nouvelle fonction** : `process_all_steps_in_order()` - ExÃ©cute les 4 Ã©tapes automatiquement
- âœ… **AmÃ©lioration** : Parse correctement les fichiers `episodes.js` au format JavaScript

### 2. `add_to_db.py` (Ajout en base de donnÃ©es)
- âœ… **FonctionnalitÃ© principale** : Insertion des donnÃ©es scrapÃ©es dans MongoDB
- âœ… **Nouvelles donnÃ©es** : Stockage du `page_count`, `scan_id`, `episodes_url` pour chaque chapitre
- âœ… **Nouvelles statistiques** : Comptage total des pages, moyenne de pages par chapitre
- âœ… **AmÃ©lioration** : Affichage enrichi des recherches avec nombre de chapitres et pages

### 3. `daily_scraper.py` (Scraping automatique)
- âœ… **FonctionnalitÃ© principale** : Scraping quotidien automatisÃ© avec scheduler
- âœ… **AmÃ©lioration** : Utilise maintenant le processus complet (4 Ã©tapes) incluant le scraping des chapitres
- âœ… **Nouvelles options** : `--test-db` pour tester la connexion MongoDB
- âœ… **Logging amÃ©liorÃ©** : Statistiques dÃ©taillÃ©es des chapitres et pages scrapÃ©s

### 4. `update_service.sh` (Mise Ã  jour automatique)
- âœ… **Script de maintenance Linux** : Automatise la mise Ã  jour du service
- âœ… **FonctionnalitÃ©s** : ArrÃªt/dÃ©marrage service, git pull, tests, vÃ©rifications
- âœ… **SÃ©curisÃ©** : VÃ©rifications Ã  chaque Ã©tape, rollback possible

### 5. `monitor_service.sh` (Surveillance)
- âœ… **Surveillance complÃ¨te** : Service, logs, espace disque, rÃ©seau
- âœ… **Options avancÃ©es** : RedÃ©marrage automatique, alertes, rapports dÃ©taillÃ©s
- âœ… **Compatible cron** : Peut Ãªtre automatisÃ© pour surveillance continue

## ğŸš€ Utilisation

### Scraping manuel complet
```bash
# ExÃ©cuter le script principal (mode interactif)
python main.py

# Puis suivre les Ã©tapes 1â†’2â†’3â†’4 dans le menu
```

### Scraping automatique en arriÃ¨re-plan
```bash
# ExÃ©cuter le scraping quotidien immÃ©diatement
python daily_scraper.py --now

# Tester la connexion Ã  la base de donnÃ©es
python daily_scraper.py --test-db
```

### Ajout manuel en base
```bash
# Ajouter les donnÃ©es du fichier JSON dans MongoDB
python add_to_db.py

# Le script utilise automatiquement anime_data.json
```

## ğŸ—„ï¸ Structure des donnÃ©es

### Collection `anime_list`
- MÃ©tadonnÃ©es des mangas
- **Nouveau** : `total_pages` - Total de pages pour tous les chapitres
- **Nouveau** : `scan_chapters` - DonnÃ©es complÃ¨tes des scans

### Collection `chapters`
- Chapitres individuels
- **Nouveau** : `page_count` - Nombre de pages du chapitre
- **Nouveau** : `scan_id` - ID du scan source
- **Nouveau** : `episodes_url` - URL du fichier episodes.js

## ğŸ“ˆ Statistiques disponibles

Le script `add_to_db.py` affiche maintenant :
- Nombre total de mangas et chapitres
- **Nouveau** : Nombre total de pages indexÃ©es
- **Nouveau** : Moyenne de pages par chapitre
- Top 5 des mangas avec le plus de chapitres (avec nombre de pages)

## ğŸ”§ DÃ©pendances requises

```bash
# Installation des dÃ©pendances
pip install -r requirements.txt

# Ou manuellement :
pip install pymongo python-dotenv schedule requests beautifulsoup4
```

## ğŸ“ Configuration MongoDB

CrÃ©er un fichier `.env` avec :
```env
MONGO_URL=mongodb+srv://username:password@cluster.mongodb.net/database_name
```

## âš¡ Tests

Pour vÃ©rifier que tout fonctionne :
```bash
python test_updated_scripts.py
```

## ğŸ• Planification automatique

### Linux (Service systemd)
```bash
# Installer le service
sudo cp anime-sama-scraper.service /etc/systemd/system/
sudo systemctl daemon-reload
sudo systemctl enable anime-sama-scraper
sudo systemctl start anime-sama-scraper

# VÃ©rifier le statut
sudo systemctl status anime-sama-scraper
```

## ğŸ”„ Mise Ã  jour du service aprÃ¨s modifications

Le script `update_service.sh` automatise complÃ¨tement la mise Ã  jour :

```bash
# Mise Ã  jour automatique (recommandÃ©e)
./update_service.sh

# Le script effectue automatiquement :
# 1. ArrÃªt du service systemd
# 2. Mise Ã  jour du code (git pull)
# 3. Installation des dÃ©pendances
# 4. Tests de validation
# 5. RedÃ©marrage du service
```

### VÃ©rification aprÃ¨s mise Ã  jour
```bash
# VÃ©rifier le statut du service
sudo systemctl status anime-sama-scraper

# Consulter les logs pour vÃ©rifier le bon fonctionnement
tail -f logs/anime_sama_scraper_$(date +%Y%m%d).log

# VÃ©rifier les logs systemd
journalctl -u anime-sama-scraper -f
```

### ğŸ“‹ Bonnes pratiques pour les mises Ã  jour

1. **Sauvegarde avant mise Ã  jour** :
   ```bash
   # Sauvegarder la base de donnÃ©es
   mongodump --uri="your_mongo_url" --out=backup_before_update
   
   # Sauvegarder les logs
   cp -r logs logs_backup_$(date +%Y%m%d)
   ```

2. **Test en local avant dÃ©ploiement** :
   ```bash
   # Tester le script en mode manuel
   python daily_scraper.py --now
   
   # VÃ©rifier les nouvelles fonctionnalitÃ©s
   python test_updated_scripts.py
   ```

3. **Surveillance aprÃ¨s mise Ã  jour** :
   ```bash
   # Surveiller les logs en temps rÃ©el
   tail -f logs/anime_sama_scraper_*.log
   ```

## ğŸ” Surveillance et maintenance du service

### Script de surveillance Linux
```bash
# VÃ©rification standard
./monitor_service.sh

# VÃ©rification dÃ©taillÃ©e avec tous les logs
./monitor_service.sh --detailed

# Surveillance avec redÃ©marrage automatique si nÃ©cessaire
./monitor_service.sh --restart

# Surveillance complÃ¨te avec alertes
./monitor_service.sh --detailed --restart --email
```

### Commandes de surveillance essentielles
```bash
# VÃ©rifier le statut du service
sudo systemctl status anime-sama-scraper

# Surveiller les logs en temps rÃ©el
tail -f logs/anime_sama_scraper_$(date +%Y%m%d).log

# VÃ©rifier les derniÃ¨res exÃ©cutions
grep "DÃ‰BUT DU PROCESSUS" logs/anime_sama_scraper_*.log | tail -5

# Voir les erreurs rÃ©centes
grep "ERROR" logs/anime_sama_scraper_*.log | tail -10

# VÃ©rifier les logs systemd
journalctl -u anime-sama-scraper --since "1 hour ago"
```

### VÃ©rifications de santÃ© pÃ©riodiques
```bash
# VÃ©rifier l'espace disque
df -h

# VÃ©rifier l'usage mÃ©moire
free -h

# VÃ©rifier les processus Python actifs
ps aux | grep python | grep -E "(daily_scraper|main\.py)"

# VÃ©rifier la connectivitÃ© vers anime-sama.fr
ping -c 3 anime-sama.fr
```

### ğŸ”„ Automatisation de la surveillance

#### Ajouter une tÃ¢che cron pour surveillance automatique
```bash
# Ã‰diter le crontab
crontab -e

# Ajouter cette ligne pour vÃ©rifier toutes les heures
0 * * * * /path/to/AnimeSamaScrapper/monitor_service.sh --restart >> /var/log/anime_sama_monitor.log 2>&1

# Ou surveillance complÃ¨te 4 fois par jour
0 6,12,18,0 * * * /path/to/AnimeSamaScrapper/monitor_service.sh --detailed --restart --email >> /var/log/anime_sama_monitor.log 2>&1
```

#### Script de nettoyage automatique des logs
```bash
# CrÃ©er un script de nettoyage
cat > cleanup_logs.sh << 'EOF'
#!/bin/bash
# Nettoyage automatique des logs anciens
find logs/ -name "*.log" -mtime +30 -exec gzip {} \;
find logs/ -name "*.log.gz" -mtime +90 -delete
journalctl --vacuum-time=30d
echo "Nettoyage des logs terminÃ©: $(date)"
EOF

chmod +x cleanup_logs.sh

# Ajouter au cron (une fois par semaine)
# 0 2 * * 0 /path/to/AnimeSamaScrapper/cleanup_logs.sh >> /var/log/cleanup.log 2>&1
```

## ğŸ› ï¸ Processus complet du scraping

Le script effectue maintenant les Ã©tapes suivantes :
1. âœ… Scrape la liste des mangas depuis anime-sama.fr
2. âœ… Parse les mÃ©tadonnÃ©es de chaque manga
3. âœ… RÃ©cupÃ¨re les informations des chapitres via episodes.js
4. âœ… Compte les pages de chaque chapitre
5. âœ… Met Ã  jour la base de donnÃ©es MongoDB
6. âœ… GÃ©nÃ¨re des logs dÃ©taillÃ©s avec statistiques

## ğŸ“Š MÃ©triques et rapports

### Logs dÃ©taillÃ©s disponibles
- Nombre de mangas traitÃ©s
- Nombre de chapitres scrapÃ©s
- Total de pages comptabilisÃ©es
- DurÃ©e du processus
- Erreurs et avertissements
- Ã‰tat de la base de donnÃ©es

### Commandes de statistiques
```bash
# Statistiques gÃ©nÃ©rales du scraping
python add_to_db.py

# Logs des derniÃ¨res exÃ©cutions
grep "STATISTIQUES FINALES" logs/anime_sama_scraper_*.log | tail -5

# Performance du scraping
grep "DurÃ©e totale" logs/anime_sama_scraper_*.log | tail -10
```

## ğŸš¨ DÃ©pannage

### ProblÃ¨mes courants et solutions

#### 1. Service qui ne dÃ©marre pas
```bash
# VÃ©rifier les logs systemd
journalctl -u anime-sama-scraper --no-pager

# VÃ©rifier la configuration du service
sudo systemctl cat anime-sama-scraper

# Tester manuellement
python daily_scraper.py --now
```

#### 2. Erreurs de connexion MongoDB
```bash
# Tester la connexion
python daily_scraper.py --test-db

# VÃ©rifier les variables d'environnement
cat .env

# Tester avec mongosh/mongo client
mongosh "$MONGO_URL"
```

#### 3. Erreurs de scraping
```bash
# VÃ©rifier la connectivitÃ©
curl -I https://anime-sama.fr

# Tester le scraping manuel
python main.py

# Analyser les logs d'erreur
grep "ERROR" logs/anime_sama_scraper_*.log | tail -20
```

#### 4. Performance lente
```bash
# VÃ©rifier l'usage des ressources
htop

# Analyser les temps de rÃ©ponse
grep "DurÃ©e" logs/anime_sama_scraper_*.log | tail -10

# VÃ©rifier l'espace disque
df -h
```

## ğŸ“ˆ RÃ©sumÃ© des amÃ©liorations

Avec ces amÃ©liorations, le systÃ¨me AnimeSamaScraper est maintenant :
- ğŸ§ **100% Linux** - DÃ©ploiement et maintenance natifs
- ğŸ“– **Complet** - Comptage prÃ©cis des pages pour chaque chapitre
- ğŸ“Š **Statistiques riches** - MÃ©triques complÃ¨tes (mangas, chapitres, pages)
- ğŸ”„ **AutomatisÃ©** - Service systemd + scripts de maintenance
- ğŸ’¾ **Robuste** - Stockage structurÃ© MongoDB avec gestion d'erreurs
- ğŸ“ˆ **MonitorÃ©** - Surveillance continue et alertes automatiques
- ğŸ› ï¸ **Maintenable** - Scripts de mise Ã  jour et diagnostic intÃ©grÃ©s

Le systÃ¨me est maintenant **prÃªt pour la production** avec une maintenance automatisÃ©e ! âœ…
